{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join   \n",
    "                           \n",
    "import pandas as pd                                  \n",
    "import dask.dataframe as dd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = db.read_text('../../data/normalization/raw_texts/ekonomi/*.txt',encoding='cp1254')\n",
    "#df = dd.read_csv('../../data/normalization/raw_texts/ekonomi/*.txt',encoding='cp1254',sep='\\n',header=None,assume_missing=True)\n",
    "#print(b.compute())\n",
    "#b.\n",
    "#files = glob.glob('../../data/normalization/raw_texts/ekonomi/*.txt')\n",
    "def read_file(path):\n",
    "    files = glob.glob(path)\n",
    "    texts=[]\n",
    "    listToStr=''\n",
    "    for file in files:\n",
    "       # open the file and then call .read() to get the text\n",
    "       with open(file,\"r\",encoding='cp1254') as f:\n",
    "          text = f.read()\n",
    "          texts.append(text)\n",
    "    listToStr =' '.join(map(str, texts))\n",
    "    return listToStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(texts, columns=[\"text\"])\n",
    "relative_path = '../../data/normalization/raw_texts';\n",
    "economy_category = '/ekonomi'\n",
    "magazine_category = '/magazin'\n",
    "medical_category = '/saglik'\n",
    "sport_category = '/spor'\n",
    "\n",
    "economy_path = relative_path + economy_category + '/*.txt'\n",
    "magazine_path = relative_path + magazine_category + '/*.txt'\n",
    "medical_path = relative_path + medical_category + '/*.txt'\n",
    "sport_path = relative_path + sport_category + '/*.txt'\n",
    "stop_words_path = relative_path + '/stopwords.txt'\n",
    "economy_str = read_file(economy_path)\n",
    "magazine_str = read_file(magazine_path)\n",
    "medical_str = read_file(medical_path)\n",
    "sport_str = read_file(sport_path)\n",
    "stop_words_str = read_file(stop_words_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from jpype import JClass, JString, getDefaultJVMPath, shutdownJVM, startJVM   \n",
    "    #shutdownJVM()\n",
    "    ZEMBEREK_PATH: str = join('..', '..', 'bin', 'zemberek-full.jar')              \n",
    "    startJVM(                                                                      \n",
    "        getDefaultJVMPath(),                                                       \n",
    "        '-ea',                                                                     \n",
    "        f'-Djava.class.path={ZEMBEREK_PATH}',                                      \n",
    "        convertStrings=False                                                       \n",
    "    )                                                                           \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word: kutucuğumuz\n",
      "\n",
      "Results:\n",
      "kutu\n",
      "\tStems = kutu, kutucuğ\n",
      "\tLemmas = kutu, kutucuğ\n",
      "kutu\n",
      "\tStems = kutu, kutucuğ\n",
      "\tLemmas = kutu, kutucuğ\n"
     ]
    }
   ],
   "source": [
    "    TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "    WordAnalysis: JClass = JClass('zemberek.morphology.analysis.WordAnalysis')\n",
    "\n",
    "    morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "\n",
    "    word: str = 'kutucuğumuz'\n",
    "\n",
    "    print(f'\\nWord: {word}\\n\\nResults:')\n",
    "\n",
    "    results: WordAnalysis = morphology.analyze(JString(word))\n",
    "    \n",
    "    for result in results:\n",
    "        print(\n",
    "            f'{str(result.getStem())}'\n",
    "            f'\\n\\tStems ='\n",
    "            f' {\", \".join([str(result) for result in result.getStems()])}'\n",
    "            f'\\n\\tLemmas ='\n",
    "            f' {\", \".join([str(result) for result in result.getStems()])}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    TurkishTokenizer: JClass = JClass('zemberek.tokenization.TurkishTokenizer')    \n",
    "    Token: JClass = JClass('zemberek.tokenization.Token')                          \n",
    "    tokenizer: TurkishTokenizer = TurkishTokenizer.DEFAULT                         \n",
    "                                                                                   \n",
    "                                                                              \n",
    "    tokenizer: TurkishTokenizer = TurkishTokenizer.builder().ignoreTypes(          \n",
    "        Token.Type.Punctuation,                                                    \n",
    "        Token.Type.NewLine,                                                        \n",
    "        Token.Type.SpaceTab,                                                       \n",
    "        Token.Type.Number,\n",
    "        Token.Type.UnknownWord,\n",
    "        Token.Type.Unknown,\n",
    "        Token.Type.URL,\n",
    "        Token.Type.WordAlphanumerical,\n",
    "        Token.Type.WordWithSymbol,\n",
    "        Token.Type.Abbreviation,\n",
    "        Token.Type.AbbreviationWithDots,\n",
    "        Token.Type.Punctuation,\n",
    "        Token.Type.PercentNumeral,\n",
    "        Token.Type.Time,\n",
    "        Token.Type.Date,\n",
    "        Token.Type.URL,\n",
    "        Token.Type.Email,\n",
    "        Token.Type.HashTag,\n",
    "        Token.Type.Mention,\n",
    "        Token.Type.MetaTag,\n",
    "        Token.Type.Emoji,\n",
    "        Token.Type.Emoticon\n",
    "    ).build() \n",
    "    \n",
    "    economy_tokenized_words = list(tokenizer.tokenize(JString(economy_str)))     \n",
    "    magazine_tokenized_words = list(tokenizer.tokenize(JString(magazine_str)))                            \n",
    "    medical_tokenized_words = list(tokenizer.tokenize(JString(medical_str)))                            \n",
    "    sport_tokenized_words = list(tokenizer.tokenize(JString(sport_str)))                            \n",
    "    stop_tokenized_words = list(tokenizer.tokenize(JString(stop_words_str)))                  \n",
    "    \n",
    "    \n",
    "    #print(len(words))                                                                        \n",
    "    #for index,token in enumerate(medical_words):                                   \n",
    "    #    print(index,token)                                                               \n",
    "                                                                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordSet = set(words)\n",
    "#print(wordSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    TurkishMorphology: JClass = JClass('zemberek.morphology.TurkishMorphology')\n",
    "    WordAnalysis: JClass = JClass('zemberek.morphology.analysis.WordAnalysis')\n",
    "\n",
    "    morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "    def getWordsStems(tokenized_words):   \n",
    "        stems = []\n",
    "        for word in tokenized_words:\n",
    "                results: WordAnalysis = morphology.analyze(JString(word.content))\n",
    "                for result in results:\n",
    "                    stems.append(str(result.getLemmas()[0]))\n",
    "        return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def removeStopWords(orginal_words,stop_words):\n",
    "        words= []\n",
    "        for word in orginal_words:\n",
    "            if (word not in stop_words):\n",
    "                words.append(word)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def mapToStringList(stop_words_str):\n",
    "        words=[]\n",
    "        for word in stop_words_str:\n",
    "            words.append(str(word.content))\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#economy_words = getWordsStems(economy_tokenized_words)\n",
    "#print(economy_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    economy_words = getWordsStems(economy_tokenized_words)\n",
    "    magazine_words = getWordsStems(magazine_tokenized_words)                             \n",
    "    medical_words = getWordsStems(medical_tokenized_words)                             \n",
    "    sport_words = getWordsStems(sport_tokenized_words) \n",
    "   \n",
    "    economy_words = removeStopWords(economy_words, mapToStringList(stop_tokenized_words))\n",
    "    magazine_words = removeStopWords(magazine_words, mapToStringList(stop_tokenized_words))\n",
    "    medical_words = removeStopWords(medical_words, mapToStringList(stop_tokenized_words))\n",
    "    sport_words = removeStopWords(sport_words, mapToStringList(stop_tokenized_words))\n",
    "    corpus_words = economy_words +magazine_words + medical_words +sport_words\n",
    "    corpus = set(economy_words +magazine_words + medical_words +sport_words)\n",
    "    #stop_tokenized_words = getWordsStems(economy_tokenized_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125255\n",
      "59338\n",
      "93668\n",
      "100582\n",
      "10198\n",
      "378843\n"
     ]
    }
   ],
   "source": [
    "#print(economy_words)\n",
    "print(len(economy_words))\n",
    "print(len(magazine_words))\n",
    "print(len(medical_words))\n",
    "print(len(sport_words))\n",
    "print(len(corpus))\n",
    "print(len(corpus_words))\n",
    "wordDictEconomy = dict.fromkeys(corpus, 0) \n",
    "wordDictMagazine = dict.fromkeys(corpus, 0) \n",
    "wordDictMedical = dict.fromkeys(corpus, 0) \n",
    "wordDictSport = dict.fromkeys(corpus, 0)\n",
    "wordDictCorpus = dict.fromkeys(corpus, 0)\n",
    "#print(wordDictEconomy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in economy_words:\n",
    "    wordDictEconomy[word]+=1\n",
    "    \n",
    "for word in magazine_words:\n",
    "    wordDictMagazine[word]+=1\n",
    "\n",
    "for word in medical_words:\n",
    "    wordDictMedical[word]+=1\n",
    "\n",
    "for word in sport_words:\n",
    "    wordDictSport[word]+=1\n",
    "    \n",
    "for word in corpus_words:\n",
    "    wordDictCorpus[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>panionios</th>\n",
       "      <th>ayman</th>\n",
       "      <th>bence</th>\n",
       "      <th>orda</th>\n",
       "      <th>görünüş</th>\n",
       "      <th>korun</th>\n",
       "      <th>nakit</th>\n",
       "      <th>stockton</th>\n",
       "      <th>enfraruj</th>\n",
       "      <th>hersek</th>\n",
       "      <th>...</th>\n",
       "      <th>enerjik</th>\n",
       "      <th>arazi</th>\n",
       "      <th>göre</th>\n",
       "      <th>yetki</th>\n",
       "      <th>bosna</th>\n",
       "      <th>cenk</th>\n",
       "      <th>şarap</th>\n",
       "      <th>döşeme</th>\n",
       "      <th>reasürans</th>\n",
       "      <th>sendika</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>407</td>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   panionios  ayman  bence  orda  görünüş  korun  nakit  stockton  enfraruj  \\\n",
       "0          0      0      2     1        0      0     11         0         0   \n",
       "1          0      0      9     0        0      0      0         0         0   \n",
       "2          0      0      0     0        0      0      0         0         2   \n",
       "3          1      2     12     0        1      1      1         1         0   \n",
       "4          1      2     23     1        1      1     12         1         2   \n",
       "\n",
       "   hersek  ...  enerjik  arazi  göre  yetki  bosna  cenk  şarap  döşeme  \\\n",
       "0       0  ...        0      2   224    177      1     2     36       0   \n",
       "1       0  ...        0      0    43      4      0    14      6       0   \n",
       "2       0  ...        2      1   103     43      0     2      0       0   \n",
       "3       1  ...        0      3    37     38      2     2      0       2   \n",
       "4       1  ...        2      6   407    262      3    20     42       2   \n",
       "\n",
       "   reasürans  sendika  \n",
       "0          5        6  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          5        6  \n",
       "\n",
       "[5 rows x 10198 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#pd.DataFrame([wordDictA, wordDictB, wordDictC ])\n",
    "pd.DataFrame([wordDictEconomy,wordDictMagazine,wordDictMedical,wordDictSport,wordDictCorpus ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination(m,n):\n",
    "    return math.factorial(m)//(math.factorial(n)*math.factorial(m-n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeMeaning(wordDictX,wordDictC,bowX,bowC):\n",
    "    meaningDict = {}\n",
    "    L = len(bowC)\n",
    "    B = len(bowX)\n",
    "    for word, count in wordDictX.items():\n",
    "        if count == 0:\n",
    "            meaningDict[word] = (count-1)*math.log10(L/B)\n",
    "        else:\n",
    "            meaningDict[word] = (-1/count)*(math.log10(combination(wordDictC[word], count)))- ((count-1)*math.log10(L/B))\n",
    "    return meaningDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meaningBowA = computeMeaning(wordDictA, wordDictC,bowA,bowC)\n",
    "#meaningBowB = computeMeaning(wordDictB, wordDictC,bowB,bowC)\n",
    "\n",
    "meaningEconomy = computeMeaning(wordDictEconomy, wordDictCorpus,economy_words,corpus)\n",
    "meaningMagazine = computeMeaning(wordDictMagazine, wordDictCorpus,magazine_words,corpus)\n",
    "meaningMedical = computeMeaning(wordDictMedical, wordDictCorpus,medical_words,corpus)\n",
    "meaningSport = computeMeaning(wordDictSport, wordDictCorpus,sport_words,corpus)\n",
    "##meaningBowB = computeMeaning(wordDictB, wordDictC,bowB,bowC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>panionios</th>\n",
       "      <th>ayman</th>\n",
       "      <th>bence</th>\n",
       "      <th>orda</th>\n",
       "      <th>görünüş</th>\n",
       "      <th>korun</th>\n",
       "      <th>nakit</th>\n",
       "      <th>stockton</th>\n",
       "      <th>enfraruj</th>\n",
       "      <th>hersek</th>\n",
       "      <th>...</th>\n",
       "      <th>enerjik</th>\n",
       "      <th>arazi</th>\n",
       "      <th>göre</th>\n",
       "      <th>yetki</th>\n",
       "      <th>bosna</th>\n",
       "      <th>cenk</th>\n",
       "      <th>şarap</th>\n",
       "      <th>döşeme</th>\n",
       "      <th>reasürans</th>\n",
       "      <th>sendika</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>-0.112280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>10.794693</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>0.501234</td>\n",
       "      <td>242.372758</td>\n",
       "      <td>191.315416</td>\n",
       "      <td>-0.477121</td>\n",
       "      <td>-0.050097</td>\n",
       "      <td>37.938141</td>\n",
       "      <td>1.089280</td>\n",
       "      <td>4.357120</td>\n",
       "      <td>5.446400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>5.461618</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>30.763458</td>\n",
       "      <td>0.223703</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>9.614891</td>\n",
       "      <td>2.704121</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.764818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>-0.778151</td>\n",
       "      <td>97.276043</td>\n",
       "      <td>39.295231</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>-0.176301</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "      <td>0.963076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>10.423141</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.079181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>1.554334</td>\n",
       "      <td>34.360315</td>\n",
       "      <td>35.568940</td>\n",
       "      <td>0.755445</td>\n",
       "      <td>-0.145372</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>0.994005</td>\n",
       "      <td>0.994005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 10198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   panionios     ayman      bence      orda   görünüş     korun      nakit  \\\n",
       "0   1.089280  1.089280  -0.112280  0.000000  1.089280  1.089280  10.794693   \n",
       "1   0.764818  0.764818   5.461618  0.764818  0.764818  0.764818   0.764818   \n",
       "2   0.963076  0.963076   0.963076  0.963076  0.963076  0.963076   0.963076   \n",
       "3   0.000000  0.994005  10.423141  0.994005  0.000000  0.000000  -1.079181   \n",
       "\n",
       "   stockton  enfraruj    hersek  ...   enerjik     arazi        göre  \\\n",
       "0  1.089280  1.089280  1.089280  ...  1.089280  0.501234  242.372758   \n",
       "1  0.764818  0.764818  0.764818  ...  0.764818  0.764818   30.763458   \n",
       "2  0.963076  0.963076  0.963076  ...  0.963076 -0.778151   97.276043   \n",
       "3  0.000000  0.994005  0.000000  ...  0.994005  1.554334   34.360315   \n",
       "\n",
       "        yetki     bosna      cenk      şarap    döşeme  reasürans   sendika  \n",
       "0  191.315416 -0.477121 -0.050097  37.938141  1.089280   4.357120  5.446400  \n",
       "1    0.223703  0.764818  9.614891   2.704121  0.764818   0.764818  0.764818  \n",
       "2   39.295231  0.963076 -0.176301   0.963076  0.963076   0.963076  0.963076  \n",
       "3   35.568940  0.755445 -0.145372   0.994005  0.994005   0.994005  0.994005  \n",
       "\n",
       "[4 rows x 10198 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame([meaningBowA, meaningBowB])\n",
    "pd.DataFrame([meaningEconomy, meaningMagazine,meaningMedical,meaningSport])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mira        -0.458023\n",
       "koşar       -0.458023\n",
       "şeffaf      -0.408458\n",
       "yapın       -0.408458\n",
       "aydan       -0.408458\n",
       "             ...     \n",
       "et         768.565882\n",
       "çok        833.996206\n",
       "al         835.742561\n",
       "ol        1619.926346\n",
       "iç        2021.616919\n",
       "Length: 10198, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([meaningEconomy, meaningMagazine,meaningMedical,meaningSport]).mean(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfEconomy = computeTF(wordDictEconomy, economy_words)\n",
    "tfMagazine = computeTF(wordDictMagazine, magazine_words)\n",
    "tfMedical = computeTF(wordDictMedical, medical_words)\n",
    "tfSport = computeTF(wordDictSport, sport_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictEconomy, wordDictMagazine,wordDictMedical,wordDictSport])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfEconomy = computeTFIDF(tfEconomy, idfs)\n",
    "tfidfMagazine = computeTFIDF(tfMagazine, idfs)\n",
    "tfidfMedical = computeTFIDF(tfMedical, idfs)\n",
    "tfidfSport = computeTFIDF(tfSport, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>panionios</th>\n",
       "      <th>ayman</th>\n",
       "      <th>bence</th>\n",
       "      <th>orda</th>\n",
       "      <th>görünüş</th>\n",
       "      <th>korun</th>\n",
       "      <th>nakit</th>\n",
       "      <th>stockton</th>\n",
       "      <th>enfraruj</th>\n",
       "      <th>hersek</th>\n",
       "      <th>...</th>\n",
       "      <th>enerjik</th>\n",
       "      <th>arazi</th>\n",
       "      <th>göre</th>\n",
       "      <th>yetki</th>\n",
       "      <th>bosna</th>\n",
       "      <th>cenk</th>\n",
       "      <th>şarap</th>\n",
       "      <th>döşeme</th>\n",
       "      <th>reasürans</th>\n",
       "      <th>sendika</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 10198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   panionios     ayman     bence      orda   görünüş     korun     nakit  \\\n",
       "0   0.000000  0.000000  0.000002  0.000005  0.000000  0.000000  0.000026   \n",
       "1   0.000000  0.000000  0.000019  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3   0.000006  0.000012  0.000015  0.000000  0.000006  0.000006  0.000003   \n",
       "\n",
       "   stockton  enfraruj    hersek  ...   enerjik     arazi  göre  yetki  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000002   0.0    0.0   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000   0.0    0.0   \n",
       "2  0.000000  0.000013  0.000000  ...  0.000013  0.000001   0.0    0.0   \n",
       "3  0.000006  0.000000  0.000006  ...  0.000000  0.000004   0.0    0.0   \n",
       "\n",
       "      bosna  cenk     şarap    döşeme  reasürans   sendika  \n",
       "0  0.000002   0.0  0.000087  0.000000   0.000024  0.000029  \n",
       "1  0.000000   0.0  0.000030  0.000000   0.000000  0.000000  \n",
       "2  0.000000   0.0  0.000000  0.000000   0.000000  0.000000  \n",
       "3  0.000006   0.0  0.000000  0.000012   0.000000  0.000000  \n",
       "\n",
       "[4 rows x 10198 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([tfidfEconomy, tfidfMagazine,tfidfMedical,tfidfSport])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutdownJVM()                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
